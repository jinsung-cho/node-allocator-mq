apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: data-passing-by-file-example-
  annotations: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.10, pipelines.kubeflow.org/pipeline_compilation_time: '2022-01-04T14:30:55.789790',
    pipelines.kubeflow.org/pipeline_spec: '{"name": "Data Passing by File Example"}'}
  labels: {pipelines.kubeflow.org/kfp_sdk_version: 1.8.10}
spec:
  entrypoint: data-passing-by-file-example
  templates:
  - name: data-passing-by-file-example
    dag:
      tasks:
      - name: read-file-and-multiply-op
        template: read-file-and-multiply-op
        dependencies: [write-file-op]
        arguments:
          artifacts:
          - {name: write-file-op-data_output, from: '{{tasks.write-file-op.outputs.artifacts.write-file-op-data_output}}'}
      - {name: write-file-op, template: write-file-op}
  - name: read-file-and-multiply-op
    container:
      args: [--data-input, /tmp/inputs/data_input/data, '----output-paths', /tmp/outputs/Output/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def read_file_and_multiply_op(
            data_input_path
        ):
            import json
            # file read to data_output_path
            with open(data_input_path, "r") as f:
                data = json.load(f)
            # multiply
            result = data["a"] * data["b"]
            print(f"Result: {result}")
            return result

        def _serialize_float(float_value: float) -> str:
            if isinstance(float_value, str):
                return float_value
            if not isinstance(float_value, (float, int)):
                raise TypeError('Value "{}" has type "{}" instead of float.'.format(
                    str(float_value), str(type(float_value))))
            return str(float_value)

        import argparse
        _parser = argparse.ArgumentParser(prog='Read file and multiply op', description='')
        _parser.add_argument("--data-input", dest="data_input_path", type=str, required=True, default=argparse.SUPPRESS)
        _parser.add_argument("----output-paths", dest="_output_paths", type=str, nargs=1)
        _parsed_args = vars(_parser.parse_args())
        _output_files = _parsed_args.pop("_output_paths", [])

        _outputs = read_file_and_multiply_op(**_parsed_args)

        _outputs = [_outputs]

        _output_serializers = [
            _serialize_float,

        ]

        import os
        for idx, output_file in enumerate(_output_files):
            try:
                os.makedirs(os.path.dirname(output_file))
            except OSError:
                pass
            with open(output_file, 'w') as f:
                f.write(_output_serializers[idx](_outputs[idx]))
      image: python:3.7
    inputs:
      artifacts:
      - {name: write-file-op-data_output, path: /tmp/inputs/data_input/data}
    outputs:
      artifacts:
      - {name: read-file-and-multiply-op-Output, path: /tmp/outputs/Output/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.10
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--data-input", {"inputPath": "data_input"}, "----output-paths",
          {"outputPath": "Output"}], "command": ["sh", "-ec", "program_path=$(mktemp)\nprintf
          \"%s\" \"$0\" > \"$program_path\"\npython3 -u \"$program_path\" \"$@\"\n",
          "def read_file_and_multiply_op(\n    data_input_path\n):\n    import json\n    #
          file read to data_output_path\n    with open(data_input_path, \"r\") as
          f:\n        data = json.load(f)\n    # multiply\n    result = data[\"a\"]
          * data[\"b\"]\n    print(f\"Result: {result}\")\n    return result\n\ndef
          _serialize_float(float_value: float) -> str:\n    if isinstance(float_value,
          str):\n        return float_value\n    if not isinstance(float_value, (float,
          int)):\n        raise TypeError(''Value \"{}\" has type \"{}\" instead of
          float.''.format(\n            str(float_value), str(type(float_value))))\n    return
          str(float_value)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Read
          file and multiply op'', description='''')\n_parser.add_argument(\"--data-input\",
          dest=\"data_input_path\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\",
          dest=\"_output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n_output_files
          = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = read_file_and_multiply_op(**_parsed_args)\n\n_outputs
          = [_outputs]\n\n_output_serializers = [\n    _serialize_float,\n\n]\n\nimport
          os\nfor idx, output_file in enumerate(_output_files):\n    try:\n        os.makedirs(os.path.dirname(output_file))\n    except
          OSError:\n        pass\n    with open(output_file, ''w'') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"],
          "image": "python:3.7"}}, "inputs": [{"name": "data_input", "type": "dict"}],
          "name": "Read file and multiply op", "outputs": [{"name": "Output", "type":
          "Float"}]}', pipelines.kubeflow.org/component_ref: '{}'}
  - name: write-file-op
    container:
      args: [--data-output, /tmp/outputs/data_output/data]
      command:
      - sh
      - -ec
      - |
        program_path=$(mktemp)
        printf "%s" "$0" > "$program_path"
        python3 -u "$program_path" "$@"
      - |
        def _make_parent_dirs_and_return_path(file_path: str):
            import os
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            return file_path

        def write_file_op(
            data_output_path
        ):
            import json
            data = {
                "a": 300,
                "b": 10,
            }
            # file write to data_output_path
            with open(data_output_path, "w") as f:
                json.dump(data, f)

        import argparse
        _parser = argparse.ArgumentParser(prog='Write file op', description='')
        _parser.add_argument("--data-output", dest="data_output_path", type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)
        _parsed_args = vars(_parser.parse_args())

        _outputs = write_file_op(**_parsed_args)
      image: python:3.7
    outputs:
      artifacts:
      - {name: write-file-op-data_output, path: /tmp/outputs/data_output/data}
    metadata:
      labels:
        pipelines.kubeflow.org/kfp_sdk_version: 1.8.10
        pipelines.kubeflow.org/pipeline-sdk-type: kfp
        pipelines.kubeflow.org/enable_caching: "true"
      annotations: {pipelines.kubeflow.org/component_spec: '{"implementation": {"container":
          {"args": ["--data-output", {"outputPath": "data_output"}], "command": ["sh",
          "-ec", "program_path=$(mktemp)\nprintf \"%s\" \"$0\" > \"$program_path\"\npython3
          -u \"$program_path\" \"$@\"\n", "def _make_parent_dirs_and_return_path(file_path:
          str):\n    import os\n    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n    return
          file_path\n\ndef write_file_op(\n    data_output_path\n):\n    import json\n    data
          = {\n        \"a\": 300,\n        \"b\": 10,\n    }\n    # file write to
          data_output_path\n    with open(data_output_path, \"w\") as f:\n        json.dump(data,
          f)\n\nimport argparse\n_parser = argparse.ArgumentParser(prog=''Write file
          op'', description='''')\n_parser.add_argument(\"--data-output\", dest=\"data_output_path\",
          type=_make_parent_dirs_and_return_path, required=True, default=argparse.SUPPRESS)\n_parsed_args
          = vars(_parser.parse_args())\n\n_outputs = write_file_op(**_parsed_args)\n"],
          "image": "python:3.7"}}, "name": "Write file op", "outputs": [{"name": "data_output",
          "type": "dict"}]}', pipelines.kubeflow.org/component_ref: '{}'}
  arguments:
    parameters: []
  serviceAccountName: pipeline-runner
